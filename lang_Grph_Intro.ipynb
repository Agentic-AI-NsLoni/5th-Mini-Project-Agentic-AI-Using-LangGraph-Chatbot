{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5056ad",
   "metadata": {},
   "source": [
    "AI AGENT / AGENTIC AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4dadd",
   "metadata": {},
   "source": [
    "# Simple AI Assist\n",
    "# In RAG Provide the External data to the APPliCATION\n",
    "\n",
    "# LLM use the Itnernal Data Then Some time O/P may be incorrect and Not up-to the mark.\n",
    "\n",
    "# Why --> Agentic AI :- Agentic AI builds AI systems that can plan, decide, and act autonomously to achieve goals, not just generate outputs.\n",
    "\n",
    "# Data-Source ---->[DB(test, pdf, image, etc)] ----> Then Give the correct answer.\n",
    "\n",
    "# Then Data-Base [DB] --> Divide into ---> Chucks.\n",
    "\n",
    "# Store Check after embbedding[numerial representationod data], it's vector database[Store all the data after the chencks].\n",
    "\n",
    "# user ask any question the go to the Vector DB then check similarity check then, agents will help to search the simmilar/relative answer, then get final answer.\n",
    "\n",
    "# Always get o/p from LLM but before have some more excesizes.\n",
    "\n",
    "|---------------------------------------------------------|\n",
    "|                                                         |\n",
    "|                                                         |\n",
    "|   I/P ------------> [LLM]  ------------> O/P            |\n",
    "|                      ^                                  |\n",
    "|   Reasoning ---------|------------ Memory               |\n",
    "|   Tools -------------|------------ etc                  |\n",
    "|                                                         |\n",
    "|---------------------------------------------------------|\n",
    "\n",
    "In above diagram LLM becomes a Agent..\n",
    "\n",
    "\n",
    "\n",
    "# I/P[Prompt] ----------> [LLM] -----------> O/P[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4bc05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af15d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27647927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2545f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e78ad96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
